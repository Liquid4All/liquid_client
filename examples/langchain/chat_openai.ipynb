{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain ChatOpenAI module with Liquid Endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/kelvin/liquid-chat/backend/venv/bin/pip: /home/kelvin/liquidapp/backend/venv/bin/python: bad interpreter: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade --quiet  langchain langchain-openai  langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    # Replace with your API key created from labs.liquid.ai\n",
    "    api_key=\"7710b77a74ae20bb32db1a5d56a03db6adba0d49e756c26c4b0484ff61905eb1\",\n",
    "    base_url=\"https://labs.liquid.ai/api/v1\",\n",
    "    model=\"liquid-beacon-1.0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send a string of text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I am an artificial intelligence language model designed to assist and engage in conversation with users. I am not a human, but I can provide information and respond to your questions or prompts based on my training data.', response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 16, 'total_tokens': 59}, 'model_name': 'liquid-beacon-1.0', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-3adec749-f4a8-461c-97de-e5591d4d9aad-0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hello, who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The largest animal on Earth is the Blue Whale (Balaenoptera musculus). It can grow up to 100 feet (30 meters) long and weigh as much as 200 tons (180 metric tonnes).', response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 20, 'total_tokens': 75}, 'model_name': 'liquid-beacon-1.0', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-92eb5863-0c35-4656-9b8e-ccd6b5542c63-0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hello, what is the largest animal on earth?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send an array of messages including system messages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'adore programmer.\", response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 41, 'total_tokens': 49}, 'model_name': 'liquid-beacon-1.0', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-a1d14b80-f474-49c5-b820-0831b08744bd-0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\"system\", \"You are a helpful assistant that translates English to French.\"),\n",
    "    (\"human\", \"Translate this sentence from English to French. I love programming.\"),\n",
    "]\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
